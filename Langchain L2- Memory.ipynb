{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b34c5b1-cf52-48ac-975a-167484875fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba361257-d0ee-47f5-8bd5-c1e5028650e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5174bcd-2359-4929-ac52-cf07b56763e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0613\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ffa9fc-b6e5-41ab-afd9-387b00229c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bd31570-5d0d-41ce-bf27-12a3b626547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= ChatOpenAI(temperature=0.0, model =llm_model)\n",
    "memory= ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e990a3fd-0f14-48b4-bd17-a2f1a4f523ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation=ConversationChain(memory=memory, \n",
    "                  llm=llm,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5c016b7-b60e-4ef8-af09-219172da68a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: How many emotional states are there?\n",
      "AI: There are generally considered to be six basic emotional states: happiness, sadness, anger, fear, surprise, and disgust. However, it's important to note that emotions can be complex and can vary greatly from person to person. Additionally, there are many other emotions that can be considered variations or combinations of these basic states.\n",
      "Human: Hi, my name is Rahul\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Rahul! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Rahul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f469f53-5515-49ef-b571-c0c59c647a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: How many emotional states are there?\n",
      "AI: There are generally considered to be six basic emotional states: happiness, sadness, anger, fear, surprise, and disgust. However, it's important to note that emotions can be complex and can vary greatly from person to person. Additionally, there are many other emotions that can be considered variations or combinations of these basic states.\n",
      "Human: Hi, my name is Rahul\n",
      "AI: Hello Rahul! It's nice to meet you. How can I assist you today?\n",
      "Human: How many emotional states are there?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"There are generally considered to be six basic emotional states: happiness, sadness, anger, fear, surprise, and disgust. However, it's important to note that emotions can be complex and can vary greatly from person to person. Additionally, there are many other emotions that can be considered variations or combinations of these basic states.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"How many emotional states are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6491393-5127-432b-ac4e-810fdeb7d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: How many emotional states are there?\n",
      "AI: There are generally considered to be six basic emotional states: happiness, sadness, anger, fear, surprise, and disgust. However, it's important to note that emotions can be complex and can vary greatly from person to person. Additionally, there are many other emotions that can be considered variations or combinations of these basic states.\n",
      "Human: Hi, my name is Rahul\n",
      "AI: Hello Rahul! It's nice to meet you. How can I assist you today?\n",
      "Human: How many emotional states are there?\n",
      "AI: There are generally considered to be six basic emotional states: happiness, sadness, anger, fear, surprise, and disgust. However, it's important to note that emotions can be complex and can vary greatly from person to person. Additionally, there are many other emotions that can be considered variations or combinations of these basic states.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Rahul.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bedadb61-4817-4ff3-a6ea-b171f355dd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39c92441-5058-4b8c-8068-27354da8e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "592bd257-4640-4956-8899-265abf4abaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Hi\"},\n",
    "                    {\"output\":\"Whats up?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06135484-849a-4625-9177-c05003289d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: Whats up?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7567ebeb-eb73-4a8b-8760-3c0d52f0dca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi\\nAI: Whats up?'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "704ae45a-4a65-42eb-aa4f-1afc362bf6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3bb760f-d197-4696-a243-db2ac0c2f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi\\nAI: Whats up?\\nHuman: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0704f-fb95-4525-a099-6dbf82ae4b9c",
   "metadata": {},
   "source": [
    "### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75c95fb0-069a-49b2-b15e-592f922652cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bff8d1e8-7984-4ace-aebc-f740e131e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2b47a01-4b6a-42ea-a382-f475666d8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c280f82-aa15-4a3d-8f65-27eed01e9f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94050a04-bee8-4e49-a5ef-6069670f8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f132d1ab-9198-4006-92ca-a5d1b42d9e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e67a0a3-7d17-46a7-b40a-79f918906721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7e1c02b-5615-4a14-84da-0caac06e02a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414f072-3a08-4238-9c28-d114469910af",
   "metadata": {},
   "source": [
    "### ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e58c1930-e5f8-4c43-a1ad-c59c332be057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4627244c-3cb4-4e4e-946b-19f96b9a6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationTokenBufferMemory(llm=llm, max_token_limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ccbdca19-a340-42f3-b608-aa9f9b849c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9644b8da-c8c9-4656-8788-6e79c2632f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: AI is what?!\\nAI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e9040-8bad-45ba-b5a8-15033437d7c4",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a72ff30b-499d-4717-9fb4-0b53bd04df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e05ef57d-1e87-4972-9de2-eae38bb2a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2f4f8bd-f285-4ad8-8976-8338d18f52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory= ConversationSummaryMemory(llm=llm, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "456a1f57-5ced-40f0-84f6-c5dbf659b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b6e33a8-4037-40ed-abce-dee54dcdfc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human greets the AI and the AI responds by asking what\\'s up. The human replies that they are not doing much, just hanging. The AI responds with a simple \"cool.\" The human then asks about the schedule for the day. The AI informs the human that there is a meeting at 8am with their product team and they need to have their powerpoint presentation prepared. From 9am to 12pm, they have time to work on their LangChain project, which will go quickly because LangChain is a powerful tool. At noon, they have lunch at an Italian restaurant with a customer who is driving from over an hour away to meet them and understand the latest in AI. The AI advises the human to bring their laptop to show the latest LLM demo.'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf34fa3c-1864-436c-b051-258e56391470",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation=ConversationChain(memory=memory, \n",
    "                  llm=llm,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c592825e-039f-44f4-a629-71eaa81c3403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human greets the AI and the AI responds by asking what's up. The human replies that they are not doing much, just hanging. The AI responds with a simple \"cool.\" The human then asks about the schedule for the day. The AI informs the human that there is a meeting at 8am with their product team and they need to have their powerpoint presentation prepared. From 9am to 12pm, they have time to work on their LangChain project, which will go quickly because LangChain is a powerful tool. At noon, they have lunch at an Italian restaurant with a customer who is driving from over an hour away to meet them and understand the latest in AI. The AI advises the human to bring their laptop to show the latest LLM demo.\n",
      "Human: What cool demo in laptop can he show\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The cool demo that you can show on your laptop is the latest LLM (Language Model) demo. It showcases the capabilities of our AI language model and how it can generate human-like text based on prompts. It's a great way to impress the customer and demonstrate the power of our AI technology.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What cool demo in laptop can he show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003b3a9-c7cb-408c-a7ab-1d77b4a221ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
